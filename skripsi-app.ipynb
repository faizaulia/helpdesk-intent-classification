{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-26T06:44:49.604227Z","iopub.execute_input":"2023-07-26T06:44:49.604638Z","iopub.status.idle":"2023-07-26T06:45:02.323683Z","shell.execute_reply.started":"2023-07-26T06:44:49.604600Z","shell.execute_reply":"2023-07-26T06:45:02.322301Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install PySastrawi","metadata":{"execution":{"iopub.status.busy":"2023-07-26T06:45:02.326113Z","iopub.execute_input":"2023-07-26T06:45:02.326576Z","iopub.status.idle":"2023-07-26T06:45:13.487340Z","shell.execute_reply.started":"2023-07-26T06:45:02.326527Z","shell.execute_reply":"2023-07-26T06:45:13.486037Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting PySastrawi\n  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PySastrawi\nSuccessfully installed PySastrawi-1.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import string\nimport re\nimport math\nfrom Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModel","metadata":{"execution":{"iopub.status.busy":"2023-07-26T06:45:13.489318Z","iopub.execute_input":"2023-07-26T06:45:13.489899Z","iopub.status.idle":"2023-07-26T06:45:18.532947Z","shell.execute_reply.started":"2023-07-26T06:45:13.489859Z","shell.execute_reply":"2023-07-26T06:45:18.531801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n  words = text.split()\n  for i in range(len(words)):\n      words[i] = re.sub(r'[^\\w]', ' ', words[i])\n  text = ' '.join(words)\n  text = ' '.join(text.split())\n    \n  stop_fact = StopWordRemoverFactory().get_stop_words()\n  more_stopword = ['bapak', 'pak', 'ibu', 'bu', 'selamat', 'pagi', 'siang', 'sore', \n                   'Bapak', 'Pak', 'Ibu', 'Bu', 'Selamat', 'Pagi', 'Siang', 'Sore',\n                   'assalamualaikum', 'assalamu', 'alaikum', 'wr', 'wb', 'ub', 'kepala', 'upt', 'universitas', 'brawijaya',\n                   'mohon', 'maaf', 'yth', 'tik', 'sti', 'bantuannya', 'ac', 'id', 'co', 'com' \n                   'Assalamualaikum', 'Assalamu', 'Wr', 'Wb', 'UB', 'Ub', 'Kepala', 'UPT', 'Universitas', 'Brawijaya',\n                   'Mohon', 'Maaf', 'Yth', 'TIK', 'STI']\n    \n  stopwords = stop_fact + more_stopword\n\n  dictionary = ArrayDictionary(stopwords)\n  str = StopWordRemover(dictionary)\n\n  text = str.remove(text)\n    \n  return text\n  ","metadata":{"execution":{"iopub.status.busy":"2023-07-26T06:45:18.535252Z","iopub.execute_input":"2023-07-26T06:45:18.536192Z","iopub.status.idle":"2023-07-26T06:45:18.729809Z","shell.execute_reply.started":"2023-07-26T06:45:18.536155Z","shell.execute_reply":"2023-07-26T06:45:18.728530Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class NaiveCustomLSTM(nn.Module):\n    def __init__(self, input_sz: int, hidden_sz: int):\n        super().__init__()\n        self.input_size = input_sz\n        self.hidden_size = hidden_sz\n        \n        #f_t forget gate\n        self.W_f = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n        self.U_f = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n        self.b_f = nn.Parameter(torch.Tensor(hidden_sz))\n        \n        #i_t input gate\n        self.W_i = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n        self.U_i = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n        self.b_i = nn.Parameter(torch.Tensor(hidden_sz))\n        \n        #g_t cell state updater\n        self.W_g = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n        self.U_g = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n        self.b_g = nn.Parameter(torch.Tensor(hidden_sz))\n        \n        #o_t output gate\n        self.W_o = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n        self.U_o = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n        self.b_o = nn.Parameter(torch.Tensor(hidden_sz))\n        \n        self.init_weights()\n    \n    def init_weights(self):\n        limit = 1.0 / math.sqrt(self.hidden_size)\n        for weight in self.parameters():\n            weight.data.uniform_(-limit, limit)\n    \n    def forward(self, x, init_states=None):\n        bs, _ = x.size()\n        \n        if init_states is None:\n            h_t, c_t = (\n                torch.zeros(bs, self.hidden_size).to(x.device),\n                torch.zeros(bs, self.hidden_size).to(x.device),\n            )\n        else:\n            h_t, c_t = init_states\n            \n        x_t = x\n        \n        f_t = torch.sigmoid(x_t @ self.W_f + h_t @ self.U_f + self.b_f)\n        i_t = torch.sigmoid(x_t @ self.W_i + h_t @ self.U_i + self.b_i)\n        g_t = torch.tanh(x_t @ self.W_g + h_t @ self.U_g + self.b_g)\n        o_t = torch.sigmoid(x_t @ self.W_o + h_t @ self.U_o + self.b_o)\n        c_t = f_t * c_t + i_t * g_t\n        h_t = o_t * torch.tanh(c_t)\n        \n        return h_t, (h_t, c_t)","metadata":{"execution":{"iopub.status.busy":"2023-07-26T06:45:18.731125Z","iopub.execute_input":"2023-07-26T06:45:18.731430Z","iopub.status.idle":"2023-07-26T06:45:18.757746Z","shell.execute_reply.started":"2023-07-26T06:45:18.731403Z","shell.execute_reply":"2023-07-26T06:45:18.756563Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, hidden_sz):\n        super().__init__()\n        self.lstm = NaiveCustomLSTM(768, hidden_sz)\n        self.fc1 = nn.Linear(hidden_sz, 7)\n        \n    def forward(self, x):\n        x_, (h_n, c_n) = self.lstm(x)\n        x_ = self.fc1(x_)\n        return x_","metadata":{"execution":{"iopub.status.busy":"2023-07-26T06:45:18.759235Z","iopub.execute_input":"2023-07-26T06:45:18.759643Z","iopub.status.idle":"2023-07-26T06:45:18.780027Z","shell.execute_reply.started":"2023-07-26T06:45:18.759610Z","shell.execute_reply":"2023-07-26T06:45:18.778717Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nmodel = AutoModel.from_pretrained(\"bert-base-multilingual-cased\", output_hidden_states=True)\nclassifier = torch.load(\"/kaggle/input/lstm-intent-classifier/final_model_tuned.pth\")\n\nin_text = input(\"Masukkan teks: \")\nclean_text = preprocess(in_text)\ntoken_text = tokenizer.encode_plus(clean_text, return_tensors=\"pt\", max_length=65, padding=\"max_length\", truncation=True)\n\nout = model(**token_text)\nlhs_out = out.last_hidden_state\nfeatures_text = lhs_out.mean(dim=1)\n\nraw_output = classifier(features_text)\nmodel_output = F.softmax(raw_output, dim=1)\n# print(\"Softmax probabilities: \", end=\"\")\n# for output in model_output:\n#     for out in output:\n#         print(\"{:0.6f}\".format(out.item()), end=\" \")\n#     print(\"\")\nconfidence, index = torch.max(model_output.data, 1)\n\nlabels = ['buat_reset_webhosting', 'gagal_login', 'masalah_vpn', 'mengajukan_email', 'nilai_it_tidak_keluar','permintaan_lisensi_office', 'ucapan_terima_kasih']\n\nprint(\"Intensi: \" + labels[index] + \"\\nConfidence: \" + str(confidence.item()))","metadata":{"execution":{"iopub.status.busy":"2023-07-26T07:45:03.748112Z","iopub.execute_input":"2023-07-26T07:45:03.748713Z","iopub.status.idle":"2023-07-26T07:45:22.872113Z","shell.execute_reply.started":"2023-07-26T07:45:03.748659Z","shell.execute_reply":"2023-07-26T07:45:22.871218Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Masukkan teks:  Bagaimana solusinya akun akses saya tidak berfungsi\n"},{"name":"stdout","text":"Intensi: ucapan_terima_kasih\nConfidence: 0.9785112738609314\n","output_type":"stream"}]}]}